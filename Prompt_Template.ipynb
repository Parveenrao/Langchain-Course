{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08HHYSA7G23L",
        "outputId": "a2abf66e-18ab-4726-affc-da42c8e3353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
            "  Downloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 orjson-3.10.6\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.17 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.2.22)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.17->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.17->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.17->langchain_google_genai) (0.1.93)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.17->langchain_google_genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.17->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.17->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain_google_genai) (2024.7.4)\n",
            "Installing collected packages: langchain_google_genai\n",
            "Successfully installed langchain_google_genai-1.0.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "5lDwJ-x2JUxm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    os.environ['GOOGLE_API_KEY'] = getpass.getpass('Enter your Google API key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQRDKjapG7kl",
        "outputId": "fcbc6b2c-a545-43e2-915d-ef7b9ed39c09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "CbAd8CtOHce-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai  as genai\n",
        "import langchain"
      ],
      "metadata": {
        "id": "hfG8M1XfHgwm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "llm = GoogleGenerativeAI(model = 'gemini-pro' , temperature = 0.9)"
      ],
      "metadata": {
        "id": "AE7NGbbCHngO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"who is the prime minister of india\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP-3-31qIm3n",
        "outputId": "156b6320-99a1-4c0b-eab1-9b8dcdc81806"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narendra Modi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatGoogleGenerativeAI(model = 'gemini-1.5-flash', temperature= 0.9)\n",
        "from langchain_core.messages import HumanMessage , SystemMessage\n",
        "message = [\n",
        "    SystemMessage(content = 'You are a standup Comedian'),\n",
        "    HumanMessage(content= 'who is the Narender Modi')\n",
        "]\n",
        "\n",
        "response = chat.invoke(message)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gni49J6oJm9a",
        "outputId": "69c36472-f05e-47dc-e4ee-f3bc2451b328"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, alright, settle down everyone!  Let's talk about Narendra Modi!  You know, the guy who's like the Oprah of India. He's got that charm, that charisma, that \"you go girl!\" energy.  He's got the whole country saying, \"Namaste, I'm ready for some change!\" \n",
            "\n",
            "He's like the ultimate selfie king, but instead of taking selfies with friends, he's taking selfies with  entire nations.  I mean, come on, the guy's got more followers on Twitter than my grandma has grandkids! \n",
            "\n",
            "And you know, he's got that whole \"make India great again\" thing going on, but instead of building walls, he's building temples.  He's like the ultimate \"spiritual entrepreneur,\" selling you dreams of a better tomorrow, one chai latte at a time.\n",
            "\n",
            "But seriously, folks, Narendra Modi is a fascinating figure.  He's a master of political maneuvering, a social media guru, and a leader who's deeply connected to his people.  Whether you love him or hate him, you gotta give him props for his ability to command attention. \n",
            "\n",
            "So, next time you're scrolling through your feed and see a picture of Narendra Modi doing a yoga pose or posing with a panda, just remember - this guy's got the world's biggest stage, and he's not afraid to use it.  \n",
            "\n",
            "(pause for applause)  \n",
            "\n",
            "So, who's ready for some jokes about the Indian economy?  Just kidding!  But seriously, I'm not a political expert.  I just like to make people laugh.  Now, if you'll excuse me, I've got a date with a plate of samosas.  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage , SystemMessage\n",
        "message = [\n",
        "    SystemMessage(content = 'You are a programmer'),\n",
        "    HumanMessage(content= 'write code for the python filter function')\n",
        "]\n",
        "\n",
        "response = chat.invoke(message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in30lhTJKJax",
        "outputId": "7b9f47b1-5274-4c8d-eef2-7871a9ce8961"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def my_filter(function, iterable):\n",
            "  \"\"\"\n",
            "  This function implements the filter functionality.\n",
            "\n",
            "  Args:\n",
            "      function: A function that takes an element as input and returns True or False.\n",
            "      iterable: An iterable object like a list, tuple, or string.\n",
            "\n",
            "  Returns:\n",
            "      A new iterable containing only the elements from the original iterable\n",
            "      where the function returned True.\n",
            "  \"\"\"\n",
            "  result = []\n",
            "  for element in iterable:\n",
            "    if function(element):\n",
            "      result.append(element)\n",
            "  return result\n",
            "\n",
            "# Example usage\n",
            "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "\n",
            "# Filter even numbers\n",
            "even_numbers = my_filter(lambda x: x % 2 == 0, numbers)\n",
            "print(f\"Even numbers: {even_numbers}\")\n",
            "\n",
            "# Filter numbers greater than 5\n",
            "greater_than_5 = my_filter(lambda x: x > 5, numbers)\n",
            "print(f\"Numbers greater than 5: {greater_than_5}\")\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1. **Function Definition:**\n",
            "   - The code defines a function called `my_filter` that takes two arguments:\n",
            "     - `function`: A function to apply as the filter condition.\n",
            "     - `iterable`: The input iterable to filter.\n",
            "\n",
            "2. **Initialization:**\n",
            "   - An empty list `result` is created to store the filtered elements.\n",
            "\n",
            "3. **Iteration:**\n",
            "   - The code iterates over each element in the `iterable` using a `for` loop.\n",
            "\n",
            "4. **Filtering:**\n",
            "   - Inside the loop, the `function` is called with the current element.\n",
            "   - If the `function` returns `True`, the element is appended to the `result` list.\n",
            "\n",
            "5. **Return:**\n",
            "   - The `my_filter` function returns the `result` list, which contains only the elements that passed the filter condition.\n",
            "\n",
            "**Example Usage:**\n",
            "\n",
            "- In the example, we filter even numbers and numbers greater than 5 from a list of numbers.\n",
            "- The `lambda` function is used to define anonymous functions that check the respective conditions.\n",
            "- The filtered results are printed using f-strings.\n",
            "\n",
            "**Note:**\n",
            "\n",
            "- This implementation mimics the functionality of the built-in `filter` function in Python. You can use the built-in `filter` function directly for a more concise solution:\n",
            "\n",
            "```python\n",
            "even_numbers = filter(lambda x: x % 2 == 0, numbers)\n",
            "greater_than_5 = filter(lambda x: x > 5, numbers)\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "Tj_GvILGKM7I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"You are vehicle mechanic , give response to the following question:{question}. Do not use techanical words , give easy to understand response\"\n",
        "prompt = PromptTemplate(template= prompt_template)\n",
        "prompt_format = prompt.format(question = \"why won't a vehicle start on ingnition\")\n",
        "response = llm.invoke(prompt_format)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6zM9wYoKZEZ",
        "outputId": "014527f8-9f7d-4d9d-99ab-be6f3056b7f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* **Battery problems:** The battery may be dead or weak, preventing it from providing enough power to start the engine.\n",
            "* **Starter issues:** The starter, which turns the engine over, may be faulty or not receiving power.\n",
            "* **Fuel supply problems:** The vehicle may not be getting enough fuel to the engine, either due to a clogged fuel filter, faulty fuel pump, or empty fuel tank.\n",
            "* **Ignition system issues:** The ignition system, which creates the spark to ignite the fuel, may be faulty. This could include problems with the spark plugs, ignition coil, or distributor.\n",
            "* **Electrical problems:** There may be a short or fault in the electrical system that is preventing the starter from getting power or the ignition system from working properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= PromptTemplate(template=\"You are electrical worker , give response to the following question:{question}.Do not use technical wrods, give easy to understand response. Your response shoudl be in the desired{language}\",input_variables=['question','language'])\n",
        "prompt_format = prompt.format(question = \"why there is fault in the factory\" , language = \"Hindi\")\n",
        "response = llm.invoke(prompt_format)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ikX2yiyKpT9",
        "outputId": "78eb2d2a-46f3-47ba-c56a-6dcb306ec138"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "फ़ैक्ट्री में फ़ॉल्ट कई कारणों से हो सकते हैं, जैसे:\n",
            "\n",
            "* **तारों में खराबी:** तार समय के साथ पुराने हो सकते हैं या क्षतिग्रस्त हो सकते हैं, जिससे शॉर्ट सर्किट या अन्य समस्याएं हो सकती हैं।\n",
            "* **उपकरणों की खराबी:** मशीनें और अन्य उपकरण समय के साथ खराब हो सकते हैं, जिससे फ़ॉल्ट हो सकते हैं।\n",
            "* **ढ़ी कनेक्शन:** यदि तारों या उपकरणों के कनेक्शन ढीले हैं, तो इससे फ़ॉल्ट हो सकते हैं।\n",
            "* **ओवरलोडिंग:** यदि फ़ैक्ट्री के सर्किट को उनकी क्षमता से अधिक लोड किया जाता है, तो इससे फ़ॉल्ट हो सकते हैं।\n",
            "* **नमी या गंदगी:** नमी या गंदगी तारों या उपकरणों को नुकसान पहुंचा सकती है, जिससे फ़ॉल्ट हो सकते हैं।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import ChatPromptTemplate , SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "l27JrtvFOOwy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "Prompt_template = PromptTemplate(\n",
        "    input_variables= ['original sentence', 'desired language'],\n",
        "    template= \" You are a language translator , an English speaker wants to translate {original_sentence} into {desired_language}.Tell him the correct anser\"\n",
        ")\n",
        "\n",
        "system_prompt = SystemMessagePromptTemplate(prompt=Prompt_template)"
      ],
      "metadata": {
        "id": "X-hqZt4GO2fz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_prompt = PromptTemplate(\n",
        "    input_variables=['original sentence' , 'desired language'],\n",
        "    template = 'Translate {original_sentence} into {desired_language}'\n",
        ")\n",
        "\n",
        "human_prompt = HumanMessagePromptTemplate(prompt = student_prompt)"
      ],
      "metadata": {
        "id": "5qWbBgCmP1FJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([system_prompt,human_prompt])\n",
        "chat_model = ChatGoogleGenerativeAI(model = 'gemini-1.5-flash', temperature = 0.9)\n",
        "\n",
        "\n",
        "llm_chain  = LLMChain(llm = chat_model , prompt= chat_prompt)\n",
        "\n",
        "input = {\n",
        "    \"original_sentence\":\"She is my girlfriend\",\n",
        "    \"desired_language\":\"Hindi\"\n",
        "}\n",
        "response = llm_chain.run(input)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ji7EK_-Z4-s",
        "outputId": "40d42bd2-a901-40cc-b32f-85a59f09f43b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The correct translation of \"She is my girlfriend\" into Hindi is: \n",
            "\n",
            "**वह मेरी प्रेमिका है** (vah meri premika hai) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few Shot Template**"
      ],
      "metadata": {
        "id": "396LmGTPj4RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [{\n",
        "    \"input\": \"The patient presented with acute exacerbation of chronic obstructive pulmonary disease, manifesting symptoms such as dyspnea, increased respiratory rate , use of accessory muscles for breathing\",\n",
        "    \"output\": \"The patient having a sudden worsening of  chronic lung diseases. This shows with difficulty breathing , fast breathing and using extra muscles to breathe\"\n",
        "}]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=['input', 'output'],\n",
        "    template = 'Input: {input}\\nOutput: {output}'\n",
        ")"
      ],
      "metadata": {
        "id": "E097Aae3j4pE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format = example_prompt.invoke(examples[0])\n",
        "print(format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TkZ8FxduBzY",
        "outputId": "f61d5655-dfdb-4e9a-b7f6-bb2599074b2b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Input: The patient presented with acute exacerbation of chronic obstructive pulmonary disease, manifesting symptoms such as dyspnea, increased respiratory rate , use of accessory muscles for breathing\\nOutput: The patient having a sudden worsening of  chronic lung diseases. This shows with difficulty breathing , fast breathing and using extra muscles to breathe'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples = examples,\n",
        "    example_prompt = example_prompt,\n",
        "    suffix = 'Question:{input}',\n",
        "    input_variables = ['input']\n",
        ")\n",
        "\n",
        "my_prompt = prompt.format(input = \"The patient has been diagonsed with hypertension, evidence by consistently elevated blood pressure readings, indicating sustained systolic and disastolic pressure above normal age\")\n",
        "response = chat.invoke(my_prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMl_ATpcvycL",
        "outputId": "aab17713-3683-4725-8194-601d2188b2ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The patient has been diagnosed with high blood pressure, as shown by repeated high blood pressure readings. This indicates that their top and bottom blood pressure numbers are consistently higher than what is considered normal for their age. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Few Shot Template With Chat Models**\n"
      ],
      "metadata": {
        "id": "T0Hj8r7USzMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate , FewShotChatMessagePromptTemplate\n",
        "\n",
        "examples = [\n",
        "\n",
        "   { \"input\":\"2 * 2\", \"output\":\"4\"},\n",
        "   { \"input\":\"3 * 3\", \"output\":\"9\"},\n",
        "   { \"input\":\"4 * 4\", \"output\":\"16\"}\n",
        "]\n",
        "\n",
        "example_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "fewshot_template = FewShotChatMessagePromptTemplate(\n",
        "    examples = examples,\n",
        "    example_prompt = example_prompt\n",
        "   )"
      ],
      "metadata": {
        "id": "VPkP0Vnr1wDk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fewshot_template.format())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm4x7Fk2V_re",
        "outputId": "9845290f-acc3-4bc6-abc6-3dc703cca1bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 2 * 2\n",
            "AI: 4\n",
            "Human: 3 * 3\n",
            "AI: 9\n",
            "Human: 4 * 4\n",
            "AI: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", 'You are mathe problem solver'),\n",
        "    fewshot_template,\n",
        "    (\"human\",\"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "iZToR0Y3bC61"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"What is the square of traingle\"\n",
        "\n",
        "response = chat.invoke(final_prompt.format(input = input))\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF5Xx91EbrTo",
        "outputId": "b0d1eb8b-a92c-46c2-cc75-7374d8243d1f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It seems like you're trying to find the area of a triangle. However, there's no such thing as the \"square of a triangle.\" \n",
            "\n",
            "To find the area of a triangle, you need:\n",
            "\n",
            "* **The base of the triangle (b)**: The length of one side of the triangle.\n",
            "* **The height of the triangle (h)**: The perpendicular distance from the base to the opposite vertex.\n",
            "\n",
            "The formula for the area of a triangle is:\n",
            "\n",
            "**Area = (1/2) * base * height** \n",
            "\n",
            "Let me know if you have the base and height of a specific triangle, and I can help you calculate its area. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}